# The output directory for the run
output_dir: runs/ntl9-synd-v1

# The total number of iterations to run
num_iterations: 150

# The basis states for the simulation
basis_states:
  # The nested directory containing the basis state files
  basis_state_dir: /nfs/lambda_stor_01/homes/abrace/projects/ddwe/src/deepdrivewe/examples/synd_ntl9_lof/bstates
  # The extension for the basis state files
  basis_state_ext: .npy
  # The number of initial ensemble members to use (should be the same as sims_per_bin in this use case)
  initial_ensemble_members: 72
  # Whether to randomly initialize the ensemble members if there
  # are more basis state files than initial ensemble members
  randomly_initialize: true

# The target threshold for the progress coordinate
# to be considered in the target state.
target_states:
    - label: folded
      pcoord: [1.0]

# The configuration for the simulation
simulation_config:
  # The path to the synd model file
  synd_model_file: /nfs/lambda_stor_01/homes/abrace/projects/ddwe/src/deepdrivewe/examples/synd_ntl9_lof/ntl9_folding.synd
  # The number of steps to run the simulation for (this includes the initial step)
  n_steps: 2
  # The reference structure for computing contact maps (getting the CA atom indices)
  reference_file: /nfs/lambda_stor_01/homes/abrace/projects/ddwe/src/deepdrivewe/examples/synd_ntl9_lof/ntl9_reference.pdb

inference_config:
  # The path to the CVAE model configuration file
  ai_model_config_path: /nfs/lambda_stor_01/homes/abrace/projects/ddwe/src/deepdrivewe/examples/synd_ntl9_lof/cvae-config.yaml
  # The path to the CVAE model weights file
  ai_model_checkpoint_path: /nfs/lambda_stor_01/homes/abrace/projects/ddwe/src/deepdrivewe/examples/synd_ntl9_lof/checkpoint-epoch-100.pt

  # The number of neighbors to use for LOF
  lof_n_neighbors: 20
  # The distance metric to use for LOF [cosine, minkowski]
  lof_distance_metric: cosine

  # The number of simulations to maintain per bin (we only have one bin)
  # so this is the total number of simulations to maintain
  sims_per_bin: 72
  # The number of simulations to resample in each iteration
  consider_for_resampling: 36
  # The maximum number of resamples to perform in each iteration
  max_resamples: 8

# The settings for the compute environment
compute_config:
  # The name of the compute environment to use (hybrid is CPU + GPU)
  name: hybrid_workstation

  cpu_config:
    # Specify we want the local parsl configuration
    name: local
    # The maximum number of worker processes to use for parallelization
    max_workers_per_node: 53

  gpu_config:
    # Specify we want the workstation parsl configuration
    name: workstation
    # Identify which GPUs to assign tasks to. It's generally recommended to first check
    # nvidia-smi to see which GPUs are available. The numbers below are analogous to
    # setting CUDA_VISIBLE_DEVICES=7
    available_accelerators: ["7"]
